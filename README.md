# NLP

![NLP](/images/logo.jpg)

## What is NLP ?

* NLP stands for Natural Language Processing, which is a part of Computer Science, Human language, and Artificial Intelligence. 

* It is the technology that is used by machines to understand, analyse, manipulate, and interpret human's languages. 

* It helps developers to organize knowledge for performing tasks such as translation, automatic summarization, Named Entity Recognition (NER), speech recognition, relationship extraction, and topic segmentation.

![NLP](/images/NLP.png)

## History of NLP

**(1940-1960)** - Focused on Machine Translation (MT)

The Natural Languages Processing started in the year 1940s.

**1948** - In the Year 1948, the first recognisable NLP application was introduced in Birkbeck College, London.

**1950**s - In the Year 1950s, there was a conflicting view between linguistics and computer science. Now, Chomsky developed his first book syntactic structures and claimed that language is generative in nature.

In **1957**, Chomsky also introduced the idea of Generative Grammar, which is rule based descriptions of syntactic structures.

**(1960-1980)** - Flavored with Artificial Intelligence (AI)

In the year **1960 to 1980**, the key developments were:

**Augmented Transition Networks (ATN)**

Augmented Transition Networks is a finite state machine that is capable of recognizing regular languages.

**Case Grammar**

Case Grammar was developed by Linguist Charles J. Fillmore in the year 1968. Case Grammar uses languages such as English to express the relationship between nouns and verbs by using the preposition.

In Case Grammar, case roles can be defined to link certain kinds of verbs and objects.

For example: "Neha broke the mirror with the hammer". In this example case grammar identify Neha as an agent, mirror as a theme, and hammer as an instrument.

In the year 1960 to 1980, key systems were:

**SHRDLU**

SHRDLU is a program written by Terry Winograd in 1968-70. It helps users to communicate with the computer and moving objects. It can handle instructions such as "pick up the green boll" and also answer the questions like "What is inside the black box." The main importance of SHRDLU is that it shows those syntax, semantics, and reasoning about the world that can be combined to produce a system that understands a natural language.

**LUNAR**

LUNAR is the classic example of a Natural Language database interface system that is used ATNs and Woods' Procedural Semantics. It was capable of translating elaborate natural language expressions into database queries and handle 78% of requests without errors.

**1980 - Current**

Till the year 1980, natural language processing systems were based on complex sets of hand-written rules. After 1980, NLP introduced machine learning algorithms for language processing.

In the beginning of the year 1990s, NLP started growing faster and achieved good process accuracy, especially in English Grammar. In 1990 also, an electronic text introduced, which provided a good resource for training and examining natural language programs. Other factors may include the availability of computers with fast CPUs and more memory. The major factor behind the advancement of natural language processing was the Internet.

Now, modern NLP consists of various applications, like speech recognition, machine translation, and machine text reading. When we combine all these applications then it allows the artificial intelligence to gain knowledge of the world. Let's consider the example of AMAZON ALEXA, using this robot you can ask the question to Alexa, and it will reply to you.

## Advantages and DisAdvantages of NLP

**Advantages of NLP**

* NLP helps us to analyse data from both structured and unstructured sources.

* NLP is very fast and time efficient.

* NLP offers end-to-end exact answers to the question. So, It saves time that going to consume unnecessary and unwanted information.

* NLP offers users to ask questions about any subject and give a direct response within milliseconds.

**Disadvantages of NLP**

* For the training of the NLP model, A lot of data and computation are required.

* Many issues arise for NLP when dealing with informal expressions, idioms, and cultural jargon.

*  results are sometimes not to be accurate, and accuracy is directly proportional to the accuracy of data.

* NLP is designed for a single, narrow job since it cannot adapt to new domains and has a limited function.

## Components of NLP

**Natural Language Understanding (NLU):**

NLU is the component of NLP that focuses on enabling machines to understand and interpret human language. It involves various tasks and techniques aimed at extracting meaning, intent, and context from text or speech. Some key components and tasks of NLU include:

**Tokenization**: Breaking text into tokens (words, subwords, sentences).

**Part-of-Speech Tagging** (POS): Assigning grammatical parts of speech to words.

**Named Entity Recognition** (NER): Identifying and classifying named entities.

**Semantic Role Labeling** (SRL): Identifying the roles of words in a sentence (subject, object, etc.).

**Coreference Resolution**: Connecting pronouns and entities to their referents.

**Intent Recognition**: Determining the user's intention or purpose in a given text or speech input.

**Slot Filling**: Extracting specific pieces of information (slots) from user queries, often used in dialogue systems and virtual assistants.

**Text Classification**: Categorizing text into predefined classes or categories (e.g., sentiment analysis, topic classification).

**Question Answering**: Developing systems that can provide accurate answers to user questions.

**Natural Language Generation (NLG):**

NLG is the component of NLP that focuses on generating human-like language from structured data or other forms of input. NLG systems take structured information and convert it into coherent and contextually appropriate text. Some key components and tasks of NLG include:

**Text Planning**: Deciding on the overall structure and content of the generated text.

**Content Selection**: Choosing relevant information and details to include in the generated text.

**Sentence Generation**: Constructing grammatically correct and coherent sentences.

**Text Summarization**: Condensing longer pieces of text into concise summaries.

**Dialogue Generation**: Creating natural and contextually appropriate responses in dialogue systems and chatbots.

**Language Style and Tone**: Adapting the generated text to a specific writing style, tone, or level of formality.

**Text Paraphrasing**: Expressing the same content in different words while maintaining the original meaning.
Storytelling: Generating narratives, stories, or creative text.